<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>html on 飞舞的尘埃</title>
    <link>/tags/html/</link>
    <description>Recent content in html on 飞舞的尘埃</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 30 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/html/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Shiny display pdf file</title>
      <link>/note/2018/04/30/shiny-display-pdf-file/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/2018/04/30/shiny-display-pdf-file/</guid>
      <description>使用pdf.js来使用在web页面中阅读PDF文件，同时禁止下载、打水印的功能
 PDF.JS 参考 PDF.js 在线pdf阅读插件（禁止打印，下载，每页水印）修改对应代码（JS/HTML）
shiny web  将修改测试无误的pdf.js保存在shiny项目的www路径下  └── www └── pdfView └── generic ├── build └── web ├── cmaps ├── images └── locale  Shiny app代码  library(shiny) # Define UI for application that draws a histogram ui &amp;lt;- fluidPage( # Application title titlePanel(&amp;#34;pdf view&amp;#34;), # Sidebar with a slider input for number of bins  uiOutput(&amp;#34;iframe_source&amp;#34;) ) server &amp;lt;- function(input, output) { output$iframe_source &amp;lt;- renderUI({ iframe_source = tags$iframe( src=sprintf(&amp;#34;pdfView/generic/web/viewer.</description>
    </item>
    
    <item>
      <title>shiny-textOuput</title>
      <link>/note/2018/04/30/shiny-textouput/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/2018/04/30/shiny-textouput/</guid>
      <description>在shiny中动态显示一个字符串变量最好使用renderText/textOutput的方法，使用renderText/reactiveValues会出现异常或不成功的情况。
 比较示例代码：
library(shiny) # Define UI for application that draws a histogram ui &amp;lt;- fluidPage( # Application title titlePanel(&amp;#34;Old Faithful Geyser Data&amp;#34;), # Sidebar with a slider input for number of bins  sidebarLayout( sidebarPanel( sliderInput(&amp;#34;bins&amp;#34;, &amp;#34;Number of bins:&amp;#34;, min = 1, max = 50, value = 30) ), # test textOutput mainPanel( div(h3(&amp;#34;固定值&amp;#34;)), div(h4(&amp;#34;text1: hello world!!&amp;#34;)), hr(), div(h3(&amp;#34;reactiveValues引入的变量值(不能显示)&amp;#34;)), div(h4(renderText(vt$numName))), hr(), div(h3(&amp;#34;textOutput动态输出&amp;#34;)), div(h4(textOutput(&amp;#34;text1&amp;#34;))), hr(), div(h3(&amp;#34;input$bins 报错&amp;#34;)), div(h4(renderText(input$bins))) ) ) ) # Define server logic required to draw a histogram server &amp;lt;- function(session, input, output) { vt = reactiveValues(numName = &amp;#39;heloo&amp;#39;) observe({ vt$numName = as.</description>
    </item>
    
    <item>
      <title>python爬虫:网页重定向问题</title>
      <link>/note/2018/03/05/crawler-url-redirect/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/note/2018/03/05/crawler-url-redirect/</guid>
      <description>使用python+requests爬虫时常常遇到请求URL地址变化（返回的URL地址不再是请求时的地址），这些很大可能是网页被重定向导致。所谓重定向(Redirect)就是通过各种方法将各种网络请求重新转到其它位置（URL）。每个网站主页是网站资源的入口，当重定向发生在网站主页时，如果不能正确处理就很有可能会错失这整个网站的内容。
 爬取网页时主要三种重定向的情况
  服务器端重定向，在服务器端完成，一般来说爬虫可以自适应，是不需要特别处理的，如响应代码301（永久重定向）、302（暂时重定向）等。具体来说，可以通过requests请求得到的response对象中的url、status_code两个属性来判断。当status_code为301、302或其他代表重定向的代码时，表示原请求被重定向；当response对象的url属性与发送请求时的链接不一致时，也说明了原请求被重定向且已经自动处理。
  客户端重定向：请求头meta refresh设置，即网页中的&amp;lt;meta&amp;gt;标签声明了网页重定向的链接，这种重定向由浏览器完成，需要编写代码进行处理。例如，某一重定向如下面的html代码第三行中的注释所示，浏览器能够自动跳转，但爬虫只能得到跳转前的页面，不能自动跳转。
如百度搜索requests后第一个结果地址https://www.baidu.com/link?url=n2d6IqviMKE2UKdm3cJo02edoksu6FX81jzThBQbkehNlFLpXO18Wry6_S3p_sp8&amp;amp;wd=&amp;amp;eqid=9b51b77c000016fb000000045a9ca929这个地址会跳转到http://www.python-requests.org/
  &amp;lt;meta http-equiv=&amp;#34;refresh&amp;#34; content=&amp;#34;0.1;url=http://www.redirectedtoxxx.com/&amp;#34;&amp;gt;&amp;lt;!--本网页会在0.1秒内refresh为url所指的网页--&amp;gt; &amp;lt;meta content=&amp;#34;always&amp;#34; name=&amp;#34;referrer&amp;#34;&amp;gt; &amp;lt;script&amp;gt;try{if(window.opener&amp;amp;&amp;amp;window.opener.bds&amp;amp;&amp;amp;window.opener.bds.pdc&amp;amp;&amp;amp;window.opener.bds.pdc.sendLinkLog){window.opener.bds.pdc.sendLinkLog();}}catch(e) {};var timeout = 0;if(/bdlksmp/.test(window.location.href)){var reg = /bdlksmp=([^=&amp;amp;]+)/,matches = window.location.href.match(reg);timeout = matches[1] ? matches[1] : 0};setTimeout(function(){window.location.replace(&amp;#34;http://www.python-requests.org/&amp;#34;)},timeout);window.opener=null;&amp;lt;/script&amp;gt; &amp;lt;noscript&amp;gt; &amp;lt;META http-equiv=&amp;#34;refresh&amp;#34; content=&amp;#34;0;URL=&amp;#39;http://www.python-requests.org/&amp;#39;&amp;#34;&amp;gt; &amp;lt;/noscript&amp;gt; 这种行为发生在客户端（浏览器），所以使用python requests 时不能实现自动跳转，返回结果仍然是原始URL地址。
import requests url = &amp;#39;https://www.baidu.com/link?url=n2d6IqviMKE2UKdm3cJo02edoksu6FX81jzThBQbkehNlFLpXO18Wry6_S3p_sp8&amp;amp;wd=&amp;amp;eqid=9b51b77c000016fb000000045a9ca929&amp;#39; r = requests.get(url) r.status_code #200 r.url #&amp;#39;https://www.baidu.com/link?url=n2d6IqviMKE2UKdm3cJo02edoksu6FX81jzThBQbkehNlFLpXO18Wry6_S3p_sp8&amp;amp;wd=&amp;amp;eqid=9b51b77c000016fb000000045a9ca929&amp;#39; 解决方法：获取真正要请求的URL，再重新requests
# xpath(&amp;#39;//meta[@http-equiv=&amp;#34;refresh&amp;#34; and @content]/@content&amp;#39;)提取出content的值 # 正则表达式提取出重定向的url import requests import re from lxml import etree def find_RealURL(url): r = requests.</description>
    </item>
    
  </channel>
</rss>